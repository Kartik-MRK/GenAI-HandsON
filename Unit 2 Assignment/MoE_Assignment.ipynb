{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cbb13ca3",
   "metadata": {},
   "source": [
    "# Unit 2 Assignment: Building a Mixture of Experts (MoE) Router\n",
    "\n",
    "**Topic:** Advanced Architecture using Groq API  \n",
    "**Tools:** Python, Groq API, Dotenv\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Build a **Smart Customer Support Router** using a Mixture of Experts (MoE) architecture.\n",
    "\n",
    "Instead of one generalist AI, we route each query to the most suitable expert:\n",
    "- **Technical Expert** → Bug reports, code errors\n",
    "- **Billing Expert** → Refunds, charges, subscriptions\n",
    "- **General Expert** → Fallback for casual chat\n",
    "\n",
    "```mermaid\n",
    "graph TD\n",
    "    User[User Query] --> Router[Router LLM\\ntemperature=0]\n",
    "    Router -->|technical| Tech[Technical Expert]\n",
    "    Router -->|billing| Bill[Billing Expert]\n",
    "    Router -->|general| Gen[General Expert]\n",
    "    Router -->|tool| Tool[Tool Function\\nmock fetch]\n",
    "    Tech & Bill & Gen & Tool --> Response[Final Answer]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73947b58",
   "metadata": {},
   "source": [
    "## Section 1: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23dffaae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\mavin\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\mavin\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~orch (C:\\Users\\mavin\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install groq python-dotenv --upgrade --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57e91d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq client initialized successfully.\n",
      "Model: llama-3.3-70b-versatile\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
    "\n",
    "client = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
    "\n",
    "# mixtral-8x7b-32768 was decommissioned — using the recommended replacement\n",
    "MODEL = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "print(\"Groq client initialized successfully.\")\n",
    "print(f\"Model: {MODEL}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd7cc60",
   "metadata": {},
   "source": [
    "## Section 2: Define Expert Configurations (`MODEL_CONFIG`)\n",
    "\n",
    "Each expert is a **different system prompt** on the same base model (`laama`).  \n",
    "This is exactly how production MoE systems simulate specialisation without fine-tuning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df4c1d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL_CONFIG defined with experts: ['technical', 'billing', 'general']\n"
     ]
    }
   ],
   "source": [
    "MODEL_CONFIG = {\n",
    "    \"technical\": {\n",
    "        \"model\": MODEL,\n",
    "        \"system_prompt\": (\n",
    "            \"You are a Senior Software Engineer and debugger. \"\n",
    "            \"You are rigorous, precise, and code-focused. \"\n",
    "            \"When given a bug report or technical question, diagnose the root cause, \"\n",
    "            \"explain it clearly, and provide a corrected code snippet where applicable. \"\n",
    "            \"Always mention the programming concept involved (e.g., off-by-one error, \"\n",
    "            \"null pointer, type mismatch).\"\n",
    "        ),\n",
    "    },\n",
    "    \"billing\": {\n",
    "        \"model\": MODEL,\n",
    "        \"system_prompt\": (\n",
    "            \"You are an empathetic and professional Billing Support Specialist. \"\n",
    "            \"You handle refund requests, duplicate charges, and subscription issues. \"\n",
    "            \"Always acknowledge the customer's frustration first, then explain the \"\n",
    "            \"company's refund policy clearly, and outline the exact steps the customer \"\n",
    "            \"should follow to resolve the issue. Be concise and reassuring.\"\n",
    "        ),\n",
    "    },\n",
    "    \"general\": {\n",
    "        \"model\": MODEL,\n",
    "        \"system_prompt\": (\n",
    "            \"You are a friendly and helpful general-purpose customer support assistant. \"\n",
    "            \"Answer casual questions politely and concisely. If the query seems to be \"\n",
    "            \"technical or billing-related, gently let the user know you can route them \"\n",
    "            \"to the right specialist.\"\n",
    "        ),\n",
    "    },\n",
    "}\n",
    "\n",
    "print(\"MODEL_CONFIG defined with experts:\", list(MODEL_CONFIG.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b44de5",
   "metadata": {},
   "source": [
    "## Section 3: The Router Function\n",
    "\n",
    "`route_prompt(user_input)` is the **brain** of the MoE system.  \n",
    "It uses `temperature=0` for deterministic, consistent classification.  \n",
    "The strict prompt forces the model to return **only** the category name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55ff5905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "route_prompt() defined.\n"
     ]
    }
   ],
   "source": [
    "VALID_CATEGORIES = [\"technical\", \"billing\", \"general\", \"tool\"]\n",
    "\n",
    "def route_prompt(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Classifies the user's query into one of: technical, billing, general, tool.\n",
    "    Uses temperature=0 for deterministic output.\n",
    "    Returns ONLY the lowercase category string.\n",
    "    \"\"\"\n",
    "    routing_prompt = (\n",
    "        \"Classify the following customer support message into exactly one of these \"\n",
    "        \"categories: [technical, billing, general, tool].\\n\\n\"\n",
    "        \"Rules:\\n\"\n",
    "        \"- 'technical': bug reports, code errors, software/hardware problems.\\n\"\n",
    "        \"- 'billing': charges, refunds, subscriptions, payments.\\n\"\n",
    "        \"- 'tool': requests for live/current data such as crypto prices, stock prices, \"\n",
    "        \"weather, exchange rates.\\n\"\n",
    "        \"- 'general': everything else.\\n\\n\"\n",
    "        \"Return ONLY the single category word in lowercase. No punctuation, no explanation.\\n\\n\"\n",
    "        f\"Message: {user_input}\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[{\"role\": \"user\", \"content\": routing_prompt}],\n",
    "        temperature=0,\n",
    "        max_tokens=10,\n",
    "    )\n",
    "\n",
    "    category = response.choices[0].message.content.strip().lower()\n",
    "\n",
    "    # Safety fallback: if the model returns something unexpected, default to 'general'\n",
    "    if category not in VALID_CATEGORIES:\n",
    "        category = \"general\"\n",
    "\n",
    "    return category\n",
    "\n",
    "\n",
    "print(\"route_prompt() defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14bdb01",
   "metadata": {},
   "source": [
    "## Section 4: The Orchestrator Function\n",
    "\n",
    "`process_request(user_input)` ties everything together:\n",
    "1. Routes the query using `route_prompt()`\n",
    "2. Selects the matching system prompt from `MODEL_CONFIG`\n",
    "3. Calls the expert LLM with `temperature=0.7` \n",
    "4. Returns the final response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fd9d1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "process_request() defined.\n"
     ]
    }
   ],
   "source": [
    "def process_request(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Main orchestrator for the MoE Customer Support Router.\n",
    "    1. Routes the query to the correct category.\n",
    "    2. Dispatches to the matching expert (or tool function).\n",
    "    3. Returns the expert's response.\n",
    "    \"\"\"\n",
    "    # Step 1: Classify the intent\n",
    "    category = route_prompt(user_input)\n",
    "    print(f\"  [Router] -> Category: '{category}'\")\n",
    "\n",
    "    # Step 2: Tool intercept (bonus) — handled before LLM call\n",
    "    if category == \"tool\":\n",
    "        return _handle_tool_request(user_input)\n",
    "\n",
    "    # Step 3: Retrieve expert config\n",
    "    expert = MODEL_CONFIG[category]\n",
    "    system_prompt = expert[\"system_prompt\"]\n",
    "    model = expert[\"model\"]\n",
    "\n",
    "    # Step 4: Call the expert LLM\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\",   \"content\": user_input},\n",
    "        ],\n",
    "        temperature=0.7,\n",
    "    )\n",
    "\n",
    "    answer = response.choices[0].message.content.strip()\n",
    "    return answer\n",
    "\n",
    "\n",
    "print(\"process_request() defined.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79571962",
   "metadata": {},
   "source": [
    "## Section 5: Test the MoE System\n",
    "\n",
    "Three test queries to validate that the router correctly dispatches to each expert.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dfd57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Test 1: My Python script is throwing an IndexError on line 5. Here is the code: my_list = [1,2,3]; print(my_list[5])\n",
      "------------------------------------------------------------\n",
      "  [Router] -> Category: 'technical'\n",
      "  [Expert Response]\n",
      "**IndexError Diagnosis**\n",
      "\n",
      "The issue in your code is an **off-by-one error**, combined with an **out-of-bounds error**. In Python, list indices start at 0 and end at `len(list) - 1`. \n",
      "\n",
      "In your case, `my_list` has 3 elements, so the valid indices are 0, 1, and 2. When you try to access `my_list[5]`, you're attempting to access an index that doesn't exist, resulting in an `IndexError`.\n",
      "\n",
      "**Corrected Code**\n",
      "\n",
      "To fix this issue, you should ensure that the index you're trying to access is within the bounds of the list. Here's an example of how to do this:\n",
      "\n",
      "```python\n",
      "my_list = [1, 2, 3]\n",
      "\n",
      "# Check if the index is within bounds before accessing\n",
      "index = 5\n",
      "if index < len(my_list):\n",
      "    print(my_list[index])\n",
      "else:\n",
      "    print(f\"Index {index} is out of bounds for list of length {len(my_list)}\")\n",
      "```\n",
      "\n",
      "Alternatively, if you want to access the last element of the list, you can use the index `-1`, which refers to the last element in Python:\n",
      "\n",
      "```python\n",
      "my_list = [1, 2, 3]\n",
      "print(my_list[-1])  # prints: 3\n",
      "```\n",
      "\n",
      "**Best Practice**\n",
      "\n",
      "To avoid similar issues in the future, always validate the index before accessing a list or other sequence types. You can also use the `try-except` block to catch and handle the `IndexError` exception:\n",
      "\n",
      "```python\n",
      "my_list = [1, 2, 3]\n",
      "index = 5\n",
      "\n",
      "try:\n",
      "    print(my_list[index])\n",
      "except IndexError:\n",
      "    print(f\"Index {index} is out of bounds for list of length {len(my_list)}\")\n",
      "```\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Test 2: I was charged twice for my subscription this month. I need a refund immediately.\n",
      "------------------------------------------------------------\n",
      "  [Router] -> Category: 'billing'\n",
      "  [Expert Response]\n",
      "I'm so sorry to hear that you were charged twice for your subscription. I can imagine how frustrating that must be for you. I'm here to help resolve this issue as quickly as possible.\n",
      "\n",
      "Our company's refund policy states that we will issue a refund for any duplicate charges within 3-5 business days. To initiate the refund process, I'll need to verify some information with you. Could you please confirm your subscription details, such as your account name and the date of the duplicate charge?\n",
      "\n",
      "Once I've verified the information, I'll go ahead and process the refund for the duplicate charge. You will receive an email notification once the refund has been issued, and the amount will be credited back to your original payment method.\n",
      "\n",
      "Please let me know if you have any questions or concerns. I'm here to assist you and ensure that this issue is resolved promptly.\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "Test 3: Hi there! What are your support hours?\n",
      "------------------------------------------------------------\n",
      "  [Router] -> Category: 'general'\n",
      "  [Expert Response]\n",
      "Hello. Our support team is available 24 hours a day, 7 days a week to help with any questions or concerns you may have. If you need assistance with a technical issue or have a billing-related question, I can also connect you with a specialist who can provide more in-depth support. How can I assist you today?\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "test_queries = [\n",
    "    # Expected: technical\n",
    "    \"My Python script is throwing an IndexError on line 5. Here is the code: my_list = [1,2,3]; print(my_list[5])\",\n",
    "    # Expected: billing\n",
    "    \"I was charged twice for my subscription this month. I need a refund immediately.\",\n",
    "    # Expected: general\n",
    "    \"Hi there! What are your support hours?\",\n",
    "]\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Test {i}: {query}\")\n",
    "    print(\"-\" * 60)\n",
    "    response = process_request(query)\n",
    "    print(f\"  [Expert Response]\\n{response}\")\n",
    "    print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659788bf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6 (Bonus): Tool Use Expert for Live Data\n",
    "\n",
    "For queries like *\"What is the current price of Bitcoin?\"*, instead of hallucinating a number, we route to a **Tool Function** that (mock) fetches real-time data.\n",
    "\n",
    "This is the foundation of **Function Calling / Tool Use** in production LLM systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31da4429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool use expert registered.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# --- Mock Tool: Crypto Price Fetcher ---\n",
    "MOCK_PRICES = {\n",
    "    \"bitcoin\":  \"$94,230.15\",\n",
    "    \"ethereum\": \"$3,412.88\",\n",
    "    \"solana\":   \"$187.42\",\n",
    "    \"dogecoin\": \"$0.1823\",\n",
    "}\n",
    "\n",
    "def fetch_crypto_price(coin: str) -> str:\n",
    "    \"\"\"Mock function that 'fetches' the current crypto price.\"\"\"\n",
    "    coin = coin.lower().strip()\n",
    "    price = MOCK_PRICES.get(coin, \"price unavailable (coin not in mock database)\")\n",
    "    return f\"[TOOL] Current price of {coin.capitalize()}: {price}  (mock data)\"\n",
    "\n",
    "\n",
    "def _handle_tool_request(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Parses the user input to extract the coin name,\n",
    "    then calls the mock fetch function.\n",
    "    \"\"\"\n",
    "    known_coins = list(MOCK_PRICES.keys())\n",
    "    user_lower = user_input.lower()\n",
    "\n",
    "    for coin in known_coins:\n",
    "        if coin in user_lower:\n",
    "            return fetch_crypto_price(coin)\n",
    "\n",
    "    # Fallback: try to extract ANY word after \"price of\" / \"cost of\"\n",
    "    match = re.search(r\"price of (\\w+)|cost of (\\w+)\", user_lower)\n",
    "    if match:\n",
    "        coin = (match.group(1) or match.group(2)).strip()\n",
    "        return fetch_crypto_price(coin)\n",
    "\n",
    "    return \"[TOOL] Could not identify the asset. Please specify a coin name (e.g., Bitcoin, Ethereum).\"\n",
    "\n",
    "\n",
    "# Add 'tool' entry to MODEL_CONFIG (for documentation purposes — dispatch is in orchestrator)\n",
    "MODEL_CONFIG[\"tool\"] = {\n",
    "    \"model\": \"tool_function\",\n",
    "    \"system_prompt\": \"Routes to a live data fetching tool instead of an LLM.\",\n",
    "}\n",
    "\n",
    "print(\"Tool use expert registered.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "107a296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query : What is the current price of Bitcoin?\n",
      "  [Router] -> Category: 'tool'\n",
      "Result: [TOOL] Current price of Bitcoin: $94,230.15  (mock data)\n",
      "\n",
      "Query : How much does Ethereum cost right now?\n",
      "  [Router] -> Category: 'tool'\n",
      "Result: [TOOL] Current price of Ethereum: $3,412.88  (mock data)\n",
      "\n",
      "Query : Tell me the price of Solana today.\n",
      "  [Router] -> Category: 'tool'\n",
      "Result: [TOOL] Current price of Solana: $187.42  (mock data)\n"
     ]
    }
   ],
   "source": [
    "tool_queries = [\n",
    "    \"What is the current price of Bitcoin?\",\n",
    "    \"How much does Ethereum cost right now?\",\n",
    "    \"Tell me the price of Solana today.\",\n",
    "]\n",
    "\n",
    "for query in tool_queries:\n",
    "    print(f\"\\nQuery : {query}\")\n",
    "    response = process_request(query)\n",
    "    print(f\"Result: {response}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2420fda",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "| Component | Role | Key Parameter |\n",
    "|-----------|------|---------------|\n",
    "| **Router** (`route_prompt`) | Classifies query intent | `temperature=0` — deterministic |\n",
    "| **Technical Expert** | Debugs code errors | `temperature=0.7` — precise |\n",
    "| **Billing Expert** | Handles refunds/charges | `temperature=0.7` — empathetic |\n",
    "| **General Expert** | Fallback for casual chat | `temperature=0.7` — friendly |\n",
    "| **Tool Expert** | Fetches live data (mock) | No LLM call — direct function |\n",
    "\n",
    "**Key Insight:** MoE doesn't require multiple models. Specialisation is achieved through **System Prompt engineering** — a zero-cost technique.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
